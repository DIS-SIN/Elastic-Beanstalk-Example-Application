{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from google.cloud import language\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USAGE NOTES\n",
    "* Ensure comments.csv, read_csv, analyze_text, and to_csv all using UTF-8\n",
    "* Delete memo.pickle if modify values returned by func analyze_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('data/comments.csv',\n",
    "                 sep=',',\n",
    "                 header=0,\n",
    "                 encoding='utf-8',      # UTF-8 for FR\n",
    "                 keep_default_na=False, # Prevent empty strings from being converted to NaN\n",
    "                 nrows=5)\n",
    "# Rename col 'stars' to 'user_stars' to keep but distinguish from new 'stars' assigned by API\n",
    "df = df.rename(columns={'stars': 'user_stars'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle for memoization\n",
    "#with open('memo.pickle', 'rb') as f:\n",
    "#    memo_dict = pickle.load(f)\n",
    "memo_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "def analyze_text(my_text, survey_id):\n",
    "    \"\"\"Pass sample to API and return tuple of shape (sentiment, magnitude).\n",
    "    Memoize results using 'survey_id' as PKEY.\"\"\"\n",
    "    if survey_id in memo_dict:\n",
    "        return memo_dict[survey_id]\n",
    "    else:\n",
    "        # Pass to API\n",
    "        document = language.types.Document(content=my_text,\n",
    "                                           type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "        sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "        # Adjust interval from [-1, 1] to [1, 5]\n",
    "        # sentiment_score = (sentiment.score * 2) + 3\n",
    "        sentiment_score = sentiment.score\n",
    "        magnitude = sentiment.magnitude\n",
    "        result = (sentiment_score, magnitude)\n",
    "        # Memoize and return result\n",
    "        memo_dict[survey_id] = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results = df.apply(lambda x: analyze_text(x['text_answer'], x['survey_id']),\n",
    "                       axis=1,               # i.e. to each row\n",
    "                       raw=False,            # Pass each cell individually as not using NumPy\n",
    "                       result_type='expand') # Return DataFrame rather than Series of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'] = api_results[0]\n",
    "df['magnitude'] = api_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export memo_dict to pickle for future re-use\n",
    "with open('memo.pickle', 'wb') as f:\n",
    "    pickle.dump(memo_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV\n",
    "df.to_csv('data/comments_ML.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the #VALUE! and #NAME! problem in Excel!!!\n",
    "# decide how to round to nearest whole\n",
    "# ensure utf-8 passed to API\n",
    "# ENSURE PROJECT IS DEAD at end, not still billing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"document\":{\n",
    "        \"type\":\"PLAIN_TEXT\",\n",
    "        \"content\":\"'Lawrence of Arabia' is a highly rated film.\"\n",
    "    },\n",
    "    \"features\":{\n",
    "        \"extractDocumentSentiment\":true\n",
    "    },\n",
    "    \"encodingType\":\"UTF8\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
