{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import pickle\n",
    "from google.cloud import language\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USAGE NOTES\n",
    "* Ensure comments.csv, read_csv, and to_csv all using UTF-8\n",
    "* Set const LOAD_FROM_PICKLE (False if e.g. changing what funcs return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_PICKLE = False\n",
    "# Ignore categorical questions stored in same table\n",
    "IGNORE_LIST = ['GCcampus Tools Used', 'OL Available', 'Prep', 'Technical Issues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('data/comments.csv',\n",
    "                 sep=',',\n",
    "                 header=0,\n",
    "                 encoding='utf-8',      # UTF-8 for FR\n",
    "                 keep_default_na=False) # Prevent empty strings from being converted to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix French chars with ANSI encodings displayed as UTF-8\n",
    "char_dict = {\n",
    "    'Ã§': 'ç',\n",
    "    'Ã‡': 'Ç',\n",
    "    'Ã©': 'é',\n",
    "    'Ã‰': 'É',\n",
    "    'Ã ': 'à',\n",
    "    'Ã¨': 'è',\n",
    "    'Ã¬': 'ì',\n",
    "    'Ã²': 'ò',\n",
    "    'Ã¹': 'ù',\n",
    "    'Ã€': 'À',\n",
    "    'Ãˆ': 'È',\n",
    "    'ÃŒ': 'Ì',\n",
    "    'Ã’': 'Ò',\n",
    "    'Ã™': 'Ù',\n",
    "    'Ã¢': 'â',\n",
    "    'Ãª': 'ê',\n",
    "    'Ã®': 'î',\n",
    "    'Ã´': 'ô',\n",
    "    'Ã»': 'û',\n",
    "    'Ã‚': 'Â',\n",
    "    'ÃŠ': 'Ê',\n",
    "    'ÃŽ': 'Î',\n",
    "    'Ã”': 'Ô',\n",
    "    'Ã›': 'Û',\n",
    "    'Ã«': 'ë',\n",
    "    'Ã¯': 'ï',\n",
    "    'Ã¼': 'ü',\n",
    "    'Ã‹': 'Ë',\n",
    "    'Ã': 'Ï', # Yes, second char is non-displaying\n",
    "    'Ãœ': 'Ü'\n",
    "}\n",
    "# Shouldn't be required for extracts from Cognos\n",
    "# df.replace(to_replace=char_dict, value=None, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle for memoization\n",
    "if LOAD_FROM_PICKLE:\n",
    "    with open('memo.pickle', 'rb') as f:\n",
    "        memo_dict = pickle.load(f)\n",
    "else:\n",
    "    memo_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "# Counter to track progress with large datasets\n",
    "ctr = 0\n",
    "\n",
    "def analyze_text(survey_id, short_question, my_text, overall_satisfaction):\n",
    "    \"\"\"Pass sample to API and return tuple of shape (sentiment, magnitude).\n",
    "    Memoize results using 'survey_id' as PKEY.\"\"\"\n",
    "    # Print ctr for every 1000 comments\n",
    "    global ctr\n",
    "    ctr += 1\n",
    "    if ctr % 1000 == 0:\n",
    "        print('Finished {0} comments!'.format(ctr))\n",
    "    \n",
    "    # Use composite key of survey_id.short_question\n",
    "    pkey = '{0}.{1}'.format(survey_id, short_question)\n",
    "    \n",
    "    if short_question in IGNORE_LIST:\n",
    "        result = ('\\\\N', '\\\\N') # i.e. NULL for MySQL\n",
    "        # No need to memoize as no expensive computation performed\n",
    "        return result\n",
    "    \n",
    "    # If already processed, returned memoized result to save compute\n",
    "    if pkey in memo_dict:\n",
    "        return memo_dict[pkey]\n",
    "    \n",
    "    # Otherwise, pass to API\n",
    "    try:\n",
    "        document = language.types.Document(content=my_text,\n",
    "                                           type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "        sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "        # Adjust interval from [-1, 1] to [1, 5]\n",
    "        # Cast to Decimal then back to int to prevent floating point rounding errors\n",
    "        sentiment_score = int(round(Decimal(str((sentiment.score * 2) + 3))))\n",
    "        magnitude = sentiment.magnitude\n",
    "        result = (sentiment_score, magnitude)\n",
    "    # Comments occasionally so badly written the API can't identify the language\n",
    "    except Exception as e:\n",
    "        print('Error {0} occurred on sample {1}'.format(e, ctr))\n",
    "        # If can't process, use overall_satisfaction from elsewhere in survey\n",
    "        result = (float(overall_satisfaction), '\\\\N')\n",
    "    # Memoize and return result\n",
    "    memo_dict[pkey] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "api_results = df.apply(lambda x: analyze_text(x['survey_id'], x['short_question'], x['text_answer'], x['overall_satisfaction']),\n",
    "                       axis=1,               # Apply to each row\n",
    "                       raw=False,            # Pass each cell individually as not using NumPy\n",
    "                       result_type='expand') # Return DataFrame rather than Series of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'] = api_results[0]\n",
    "df['magnitude'] = api_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export memo_dict to pickle for future re-use\n",
    "with open('memo.pickle', 'wb') as f:\n",
    "    pickle.dump(memo_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV; export locally as slow to write to USB\n",
    "df.to_csv('data/comments_ML.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
